# 任务型对话

任务型对话分为流水线方法、端到端方法。

## 流水线方法

​	流水线方法主要包括语音识别（ASR）、自然语言理解（NLU）、对话管理（DM）、自然语言生成（NLG)、语音合成(TTS)。首尾两个过程在本篇不讨论。

![image-20210719164840078](./imgs/任务型对话/管道方法框架图)

### NLU

​	NLU的目的是将用户输入映射到根据不同场景定义的任务的目标中，通常包括三个任务：领域识别、意图检测、语义槽填充。前两者通常属于文本分类任务、语义槽填充本质上属于序列标注任务。

（有没有一个完整流程的模型例子）

![image-20210719164856381](./imgs/任务型对话/NLU代表性方法)

### DM

​	DM的输入是NLU的三元组输出，并需要考虑历史对话信息和上下文的语境等信息进行全面分析，决定系统要采取的相应的动作。DM主要有对话状态追踪(DST)和生成对话策略(DP)两个过程。

​	对话状态是一种将t时刻的对话表示为可供系统选择下一时刻动作信息的数据结构。

### DST

​	DST以当前动作$u_n$，前n-1轮的对话状态和相应的系统动作作为输入，输出其对当前对话状态$S_n$的估计。对话策略的选择依赖于DST估计的对话状态$S_t$。

DST主要分为三类方法：基于人工规则、基于生成式模型和基于判别式模型。

![image-20210719164934509](./imgs/任务型对话/DM代表方法0)

​	生成式模型是从训练数据中学习相关联合概率密度分布，计算出所有对话状态的条件概率分布作为预测模型。

​	基于判别式的模型，将DST当做分类任务，直接学习后验分布对模型优化。

### DP

​	对话策略根据DST估计的对话状态$S_t$，通过预设的候选动作集合，选择系统动作或策略$a_n$.

DP需要基于目前状态$S_i$和可能的动作来选择最高累计奖励的动作。

​	对话策略可以通过监督学习、强化学习和模仿学习得到。

#### 概念

​	监督学习需要专家手工设计对话策略规则，通过上一步生成的动作进行监督学习。

​	强化学习通过一个马尔科夫决策过程（MDP），寻找最优策略的过程。MDP可描述为五元组(S,A,P,R,$\gamma$)。

S：表示所有可能状态的集合，即状态集；

A：针对每个状态，做出动作的集合，即动作集；

P：表示哥哥状态之间的转移概率；

R：表示各个状态之间的转换获得的对应回报，即奖励函数。

$\gamma$：表示为折扣因子，用来计算累计奖励。

​	在序列多步决策问题中，强化学习需要频繁地试错，来获得稀疏的奖励。

​	模仿学习的原理是通过给智能体提供先验知识，从而学习、模仿人类行为。

![image-20210719164952931](./imgs/任务型对话/DM代表方法1)

### NLG

​	自然语言生成的主要任务是将DM模块输出的抽象表达转换为句法合法、语义准确的自然语言句子。NLG的方法可以划分为：基于规则模板/句子规划的方法、基于统计语言模型的方法和基于深度学习的方法。

#### 概念

​	基于模板的方法需要扔给你个设定对话场景，并根据每个对话场景设计对话模板，这些模板的某些成分是固定的，而另一部分需要根据DM模块的输出填充模板。

![image-20210719164711102](./imgs/任务型对话/NLG代表性方法)

## 端到端方法

![image-20210719164750444](./imgs/任务型对话/端到端方法框架图)

基于监督学习框架

- 基于内存的端到端模型
- 基于神经网络的端到端可训练模型
- 基于注意力的拷贝机制的序列到序列模型
- 一个端到端的可训练的键值检索网络

基于强化学习框架

- 深度循环Q网络(DRQN)
- 端到端的KB-InfoBot

监督学习结合深度学习或强化学习框架

- 混合编码网络(HCN)
- 基于神经网络的端到端框架

![image-20210719164729272](./imgs/任务型对话/端到端方法代表方法)



来源：计算机学报《任务型对话系统研究综述》，赵阳洋等

